{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Seminar\n",
    "\n",
    "Collaborative Filtering recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "import lightfm\n",
    "import lightfm.data as ld\n",
    "import lightfm.evaluation as lv\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import optuna\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'..\\data\\recsys-in-practice\\train_joke_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = data[data[\"Rating\"] > 5].copy()\n",
    "positives[\"test\"] = np.random.random(len(positives)) >= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = positives[~positives[\"test\"]].groupby(\"UID\").size()\n",
    "users = set(user_counts[user_counts >= 5].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = positives[~positives[\"test\"]].groupby(\"JID\").size()\n",
    "tracks = set(track_counts[track_counts >= 5].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245506, 101889)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = positives[~positives[\"test\"] & positives[\"UID\"].isin(users) & positives[\"JID\"].isin(tracks)]\n",
    "test_data = positives[positives[\"test\"] & positives[\"UID\"].isin(users) & positives[\"JID\"].isin(tracks)]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ld.Dataset()\n",
    "dataset.fit(users, tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, _ = dataset.build_interactions(train_data[[\"UID\", \"JID\"]].itertuples(index=False, name=None))\n",
    "test_interactions, _ = dataset.build_interactions(test_data[[\"UID\", \"JID\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(epochs=1, at=10, loss=\"warp\", no_components=30, learning_rate=0.01, max_sampled=10, user_alpha=0.0, item_alpha=0.0, threads=30, verbose=False):\n",
    "    model = lightfm.LightFM(\n",
    "        no_components=no_components,\n",
    "        loss=loss,\n",
    "        learning_rate=learning_rate,\n",
    "        max_sampled=max_sampled,\n",
    "        user_alpha=user_alpha,\n",
    "        item_alpha=item_alpha,\n",
    "    )\n",
    "\n",
    "    precisions_at = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model = model.fit_partial(train_interactions, num_threads=threads)\n",
    "        precision_at = lv.precision_at_k(model, test_interactions, train_interactions=train_interactions, k=at, num_threads=threads)\n",
    "        if verbose:\n",
    "            print(f\"{epoch}:\\t{np.mean(precision_at)} +/- {ss.sem(precision_at) * 1.96}\")\n",
    "        precisions_at.append(np.mean(precision_at))\n",
    "        \n",
    "    return model, precisions_at\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    loss = trial.suggest_categorical(\"loss\", [\"warp\", \"bpr\"])\n",
    "    no_components = trial.suggest_categorical(\"no_components\", [10, 30, 50])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [0.0001, 0.001, 0.01])\n",
    "    max_sampled = trial.suggest_categorical(\"max_sampled\", [10, 20, 50, 100])\n",
    "    user_alpha = trial.suggest_categorical(\"user_alpha\", [0.0, 0.0001])\n",
    "    item_alpha = trial.suggest_categorical(\"item_alpha\", [0.0, 0.0001])\n",
    "    \n",
    "    model, precisions_at = fit_model(\n",
    "        epochs=5, \n",
    "        at=10,\n",
    "        loss=loss,\n",
    "        no_components=no_components, \n",
    "        learning_rate=learning_rate, \n",
    "        max_sampled=max_sampled, \n",
    "        user_alpha=user_alpha, \n",
    "        item_alpha=item_alpha,\n",
    "    )\n",
    "    \n",
    "    return precisions_at[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:44:08,642]\u001b[0m A new study created in memory with name: no-name-f3d9b074-f352-4b63-8727-0973322312b6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'loss': 'warp',\n",
    " 'no_components': 50,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_sampled': 20,\n",
    " 'user_alpha': 0.0,\n",
    " 'item_alpha': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, precisions_at = fit_model(\n",
    "    epochs=100,\n",
    "    at=10,\n",
    "    loss=best_params[\"loss\"],\n",
    "    no_components=best_params[\"no_components\"], \n",
    "    learning_rate=best_params[\"learning_rate\"], \n",
    "    max_sampled=best_params[\"max_sampled\"],\n",
    "    user_alpha=best_params[\"user_alpha\"],\n",
    "    item_alpha=best_params[\"item_alpha\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = pl.subplots()\n",
    "\n",
    "ax.plot(np.arange(len(precisions_at)), precisions_at)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save track embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases, embeddings = model.get_item_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.item_biases *= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_meta = pd.read_json(DATA_DIR + \"tracks.json\", lines=True)\n",
    "track_meta[\"dataset_index\"] = track_meta[\"track\"].map(lambda t: dataset.mapping()[2].get(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tracks = track_meta[pd.notnull(track_meta[\"dataset_index\"])].sort_values(\"dataset_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tb.SummaryWriter(comment='msd_ligtfm_embeddings', log_dir=DATA_DIR + \"tb\")\n",
    "writer.add_embedding(embeddings, metadata=list(dataset_tracks[[\"artist\", \"title\"]].itertuples(index=False, name=None)), tag=\"lightfm\", metadata_header=[\"artist\", \"title\"])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = dataset_tracks[\"track\"].values\n",
    "users = [user for user, index in sorted(dataset.mapping()[0].items(), key=lambda kv: kv[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"recommendations.json\", \"w\") as rf:\n",
    "    for user_index in tqdm.tqdm(range(dataset.user_features_shape()[0])):\n",
    "        predictions = model.predict(user_index, np.arange(dataset.item_features_shape()[0]), num_threads=30)\n",
    "        top = tracks[np.argsort(predictions)[-100:]]\n",
    "        recommendation = {\n",
    "            \"UID\": int(users[user_index]),\n",
    "            \"tracks\": [int(x) for x in top]\n",
    "        }\n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
