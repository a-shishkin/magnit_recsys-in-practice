{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcbea09",
   "metadata": {},
   "source": [
    "# Comparing matrix factorization with transformers for MovieLens recommendations using PyTorch-accelerated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4220e",
   "metadata": {},
   "source": [
    "By Chris Hughes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d206280",
   "metadata": {},
   "source": [
    "The package versions used are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145f3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5666bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "import tensorboardX as tb\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77708af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca536465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72ab90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06045473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joke_df = pd.read_csv(r'..\\data\\recsys-in-practice\\train_joke_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007ffeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joke_df[\"UID\"] = train_joke_df[\"UID\"].astype(int)\n",
    "train_joke_df[\"JID\"] = train_joke_df[\"JID\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae91343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating = train_joke_df['Rating'].values\n",
    "#print(np.min(rating), np.max(np.abs(rating)), np.max(np.abs(rating)))\n",
    "\n",
    "#rating_norm = (rating - np.min(rating)) / (np.max(rating) - np.min(rating))\n",
    "#rating_norm = rating / np.max(np.abs(rating))\n",
    "#print(np.min(rating_norm), np.max(rating_norm))\n",
    "\n",
    "#train_joke_df['Rating_norm'] = rating_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7fdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eadcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_joke_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b569c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717bdff",
   "metadata": {},
   "source": [
    "Even when considering model benchmarks on the same dataset, to have a fair comparison, it is important to understand how the data has been split and to make sure that the approaches taken are consistent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f180563",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lookup = {v: i+1 for i, v in enumerate(train_joke_df[\"UID\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99971bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lookup = {v: i+1 for i, v in enumerate(train_joke_df[\"JID\"].unique())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca6eda",
   "metadata": {},
   "source": [
    "Now that we can encode our features, as we are using PyTorch, we need to define a Dataset to wrap our DataFrame and return the user-item ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8e1a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9909b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class UserItemRatingDataset(Dataset):\n",
    "    def __init__(self, df, movie_lookup, user_lookup):\n",
    "        self.df = df\n",
    "        self.movie_lookup = movie_lookup\n",
    "        self.user_lookup = user_lookup\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        user_id = torch.tensor(self.user_lookup[row.UID]).to(device)\n",
    "        movie_id = torch.tensor(self.movie_lookup[row.JID]).to(device)\n",
    "        \n",
    "        rating = torch.tensor(row.Rating, dtype=torch.float32).to(device)\n",
    "        \n",
    "        return (user_id, movie_id), rating\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38640a64",
   "metadata": {},
   "source": [
    "We can now use this to create our training and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df035b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UserItemRatingDataset(train_df, movie_lookup, user_lookup)\n",
    "valid_dataset = UserItemRatingDataset(valid_df, movie_lookup, user_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933d4a3",
   "metadata": {},
   "source": [
    "Next, let's define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f95c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MfDotBias(nn.Module):\n",
    "\n",
    "    def __init__(self, n_factors, n_users, n_items, ratings_range=None):\n",
    "        super().__init__()\n",
    "        self.y_range = ratings_range\n",
    "        self.user_embedding = nn.Embedding(n_users+1, n_factors, padding_idx=0)\n",
    "        self.item_embedding = nn.Embedding(n_items+1, n_factors, padding_idx=0)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        users, items = inputs\n",
    "        dot = self.user_embedding(users) * self.item_embedding(items)\n",
    "        result = dot.sum(1)\n",
    "\n",
    "        if self.y_range is None:\n",
    "            return result\n",
    "        else:\n",
    "            return (torch.sigmoid(result) * (self.y_range[1] - self.y_range[0]) + self.y_range[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f7c68",
   "metadata": {},
   "source": [
    "As we can see, this is very simple to define. Note that because an embedding layer is simply a lookup table, it is important that when we specify the size of the embedding layer, it must contain any value that will be seen during training and evaluation. Because of this, we will use the number of unique items observed in the full dataset to do this, not just the training set. We have also specified a padding embedding at index 0, which can be used for any unknown values. PyTorch handles this by setting this entry to a zero-vector, which is not updated during training.\n",
    "\n",
    "Additionally, as this is a regression task, the range that the model could predict is potentially unbounded. While the model can learn to restrict the output values to between 1 and 5, we can make this easier for the model by modifying the architecture to restrict this range prior to training. We have done this by applying the sigmoid function to the model's output - which restricts the range to between 0 and 1 - and then scaling this to within a range that we can define."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d17da",
   "metadata": {},
   "source": [
    "### Train with PyTorch accelerated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03b619",
   "metadata": {},
   "source": [
    "At this point, we would usually start writing the training loop; however, as we are using pytorch-accelerated, this will largely be taken care of for us. However, as pytorch-accelerated tracks only the training and validation losses by default, let's create a callback to track our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85e7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33053722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2a4ff4",
   "metadata": {},
   "source": [
    "Let's create a callback to track our metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc26c9d",
   "metadata": {},
   "source": [
    "Now, all that is left to do is to train the model. PyTorch-accelerated provides a notebook_launcher function, which enables us to run multi-GPU training runs from within a notebook. To use this, all we need to do is to define a training function that instantiates our Trainer object and calls the train method.\n",
    "\n",
    "Components such as the model and dataset can be defined anywhere in the notebook, but it is important that the trainer is only ever instantiated within a training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d114276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def save(model, name):\n",
    "    os.mkdir(f\"artifacts_wonderfund_v1_fin/{name}\")\n",
    "    #torch.save(model, f\"{name}/model.pkl\")\n",
    "    torch.save(model.state_dict(), f\"artifacts_wonderfund_v1_fin/{name}/checkpoint.pth\")\n",
    "    \n",
    "def load(name):\n",
    "    return torch.load(f\"artifacts_wonderfund_v1_fin/{name}/model.pkl\")\n",
    "\n",
    "def load2(name, model):\n",
    "    model.load_state_dict(torch.load(f\"artifacts_wonderfund_v1_fin/{name}/checkpoint.pth\"))\n",
    "    \n",
    "def train_model(epoch_start, model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler, loss_train_history,\n",
    "                loss_val_history):   \n",
    "    bet_model_name = None\n",
    "    best_loss = compute_accuracy(model, val_loader, loss)\n",
    "    print('loss:', best_loss)\n",
    "    for epoch in range(epoch_start, epoch_start + num_epochs):     \n",
    "        t1 = time.time()\n",
    "        model.train()   \n",
    "        loss_accum = 0\n",
    "        for i_step, (x, y) in enumerate(tqdm(train_loader)):\n",
    "            prediction = model(x)    \n",
    "            loss_value = loss(prediction, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()            \n",
    "            loss_accum += loss_value.cpu().detach().numpy()\n",
    "\n",
    "            \n",
    "        \n",
    "        ave_loss = loss_accum / (i_step + 1)\n",
    "        loss_val = compute_accuracy(model, val_loader, loss)\n",
    "        \n",
    "        loss_train_history.append(float(ave_loss))\n",
    "        loss_val_history.append(loss_val)\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step(loss_val)\n",
    "            \n",
    "\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            bet_model_name = f'{datetime.datetime.now().strftime(\"%d.%m.%Y_%H.%M.%S.%f\")}_epoch_{epoch}_loss_{round(best_loss, 4)}'\n",
    "            save(model, bet_model_name)\n",
    "            print(f\"saved {bet_model_name}\")\n",
    "\n",
    "            \n",
    "        print(\"Epoch: %i lr: %f; Train loss: %f, Val loss: %f, time: %i s\" % (epoch, get_lr(optimizer), ave_loss, loss_val,\n",
    "                                                                            round(time.time() - t1)))\n",
    "    return bet_model_name\n",
    "        \n",
    "    \n",
    "def compute_accuracy(model, loader, loss):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    loss_accum = 0\n",
    "    for i_step, (x, y) in enumerate(tqdm(loader)):\n",
    "        prediction = model(x)\n",
    "        loss_value = loss(prediction, y)\n",
    "        loss_accum += loss_value.cpu().detach().numpy()\n",
    "\n",
    "    ave_loss = loss_accum / (i_step + 1)         \n",
    "    return float(ave_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "030563cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_loss(prediction, target):\n",
    "    return torch.sqrt(nn.MSELoss()(prediction, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad310c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MfDotBias(120, len(user_lookup), len(movie_lookup), ratings_range=[-10, 10]).to(device)\n",
    "loss_train_history, loss_val_history = [], []\n",
    "\n",
    "#best_model_name = '22.04.2023_19.04.16.683005_epoch_14_loss_5.6441'\n",
    "#load2(best_model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5fc6fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9094f7d9309a4f5b9461444a9536aaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 10.659584045410156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e529d43350476eaa35ebb22b41aca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e471bbcf284fb6a7925346b23287a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_03.36.33.744548_epoch_0_loss_10.6055\n",
      "Epoch: 0 lr: 0.010000; Train loss: 10.641962, Val loss: 10.605471, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3571feb1ca094fd68cee37e7775bbd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cc14052929419cb18525980674a4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_03.42.03.671491_epoch_1_loss_10.5345\n",
      "Epoch: 1 lr: 0.010000; Train loss: 9.944235, Val loss: 10.534550, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde4c61eb5694c4682366cd7e46abb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047a86d7f11c466b852c1d81d10a35de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_03.47.33.729849_epoch_2_loss_10.4538\n",
      "Epoch: 2 lr: 0.010000; Train loss: 9.490548, Val loss: 10.453848, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb92d2dcf0d9467b878f2845f5d71ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3866e1cce6844437aaa452f0735911b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_03.53.01.902113_epoch_3_loss_10.3522\n",
      "Epoch: 3 lr: 0.010000; Train loss: 9.158998, Val loss: 10.352179, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6ca4284688412880424b9cb2792ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812094f78c9748a593adbd970bac0fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_03.58.30.085934_epoch_4_loss_10.2146\n",
      "Epoch: 4 lr: 0.010000; Train loss: 8.858001, Val loss: 10.214646, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9fcd687e2349afbef2494e30698d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea4b3ae51cd4de8af7b7a43977e47b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.03.57.797395_epoch_5_loss_9.9911\n",
      "Epoch: 5 lr: 0.010000; Train loss: 8.542657, Val loss: 9.991148, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bdade4c6224a798a56bd428f6c6685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15d855e283d4553894328017153684a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.09.27.899606_epoch_6_loss_9.4784\n",
      "Epoch: 6 lr: 0.010000; Train loss: 8.142444, Val loss: 9.478393, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fcfe76f6b14beaa04aa351f9c71c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2dc7694684478fbe27c91ed13b694c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.14.57.587009_epoch_7_loss_8.0097\n",
      "Epoch: 7 lr: 0.010000; Train loss: 7.382322, Val loss: 8.009691, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8c554486cc4a988a183359d275d3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1137a42af1fa440ba1d3b27e9bb5e6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.20.26.137421_epoch_8_loss_6.5129\n",
      "Epoch: 8 lr: 0.010000; Train loss: 6.171665, Val loss: 6.512869, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dd4230c31a485ca1520764894dcba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6b5f73bc8d47a7a7824dd79213032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.25.55.708705_epoch_9_loss_5.7024\n",
      "Epoch: 9 lr: 0.010000; Train loss: 5.303132, Val loss: 5.702438, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78569f1a71c9498cbdfed13561ebd328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26f4e9e3d16463eac155beacba24648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.31.23.649879_epoch_10_loss_5.1791\n",
      "Epoch: 10 lr: 0.010000; Train loss: 4.747838, Val loss: 5.179125, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df86357355944129d94c8c291becc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd73f771bec84fbe810610a2a3c9081c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.36.53.602449_epoch_11_loss_4.812\n",
      "Epoch: 11 lr: 0.010000; Train loss: 4.342927, Val loss: 4.811973, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ec2dcefc62416e90f9daa1aa1e81b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68764e0e7b6a4303aec8c5da9652313e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 26.04.2023_04.42.21.074233_epoch_12_loss_4.7006\n",
      "Epoch: 12 lr: 0.010000; Train loss: 4.069269, Val loss: 4.700571, time: 327 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061cd910c1a24108b807aafe5b8f9da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaf762899574a6fa7581b60546ef860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 lr: 0.010000; Train loss: 3.905332, Val loss: 4.718125, time: 327 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ee2490efa94940af848c2662abbbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b22ee0db0a49e3ae0ec78825e5829b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 lr: 0.010000; Train loss: 3.781053, Val loss: 4.779791, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50daa52b88564d198adea98d72430418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683c1711536d4cc495f5a3ae2079366a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 lr: 0.010000; Train loss: 3.661637, Val loss: 4.856554, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8249f654b68d4a8fb6ba253d2edf81f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcad19fd4cb49c48a6317fc8410099c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 lr: 0.010000; Train loss: 3.541625, Val loss: 4.946005, time: 327 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d05ced13bce443da606d61d3cce5d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93823f0894de4eb1835d3c7f72a30616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 lr: 0.010000; Train loss: 3.417273, Val loss: 5.045613, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfcfcd23adc45cd8f471b0671f1f108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42572e67d1e4adba98c523549640092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18 lr: 0.001000; Train loss: 3.284104, Val loss: 5.151411, time: 332 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7510c3cc343744f8b7f99f0ad204027e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f099eb768709414783203cf0ede2056f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 lr: 0.001000; Train loss: 3.136309, Val loss: 4.983895, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a116a03ddb6483dacc413ea13144dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10195d60450d4f15b4cff382bae62f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 lr: 0.001000; Train loss: 2.926367, Val loss: 4.923730, time: 333 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d2934fe00c4bcea06b5c88c0a7af37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc17bb2c850143b097da52a51a48398a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 lr: 0.001000; Train loss: 2.855093, Val loss: 4.902714, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab6d1ee82344b9fbad4695478f08d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744b10ff7bf448f096c49ddca22a700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 lr: 0.001000; Train loss: 2.817178, Val loss: 4.897458, time: 333 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a64132751d4458a22c7e00073a9a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cc1ca225574a3eb52ee6c3ac825eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 lr: 0.001000; Train loss: 2.787514, Val loss: 4.899930, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a2c27277cb474eacb7992d61916a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e1bbb0b990433190bfa2b9b3fec15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 24 lr: 0.000100; Train loss: 2.760367, Val loss: 4.906473, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b19d8ca4e9475bb17fcc55d58e047c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77ce62c4cb7497b900346b61b8ef231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 lr: 0.000100; Train loss: 2.703323, Val loss: 4.907047, time: 327 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376bd3c7709547ba809b0a70247d4fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2129fb0386b744778c37b642cf20f2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 lr: 0.000100; Train loss: 2.700417, Val loss: 4.907697, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67057e776a844b52b604659664606e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f48d7b9b08c4870bca23d9a1a8d4788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 lr: 0.000100; Train loss: 2.697540, Val loss: 4.908384, time: 332 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8b714470fd482c9c538aba38ba7d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a9a41a5a4d444aadb66055f76c056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 lr: 0.000100; Train loss: 2.694713, Val loss: 4.909104, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e22c8b55e54d9aac4c061651a63b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42778ecfa8144b21b513c329693ac305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 lr: 0.000100; Train loss: 2.691924, Val loss: 4.909855, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6745b269fb0444aaeca9b0c8e64159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7834d9292ff4a08bdf13c0325c4e4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch: 30 lr: 0.000010; Train loss: 2.689164, Val loss: 4.910633, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df824b6b7bc4428add853ae46713cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6345d617d8ad408c9c91734f07dd4f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 lr: 0.000010; Train loss: 2.683401, Val loss: 4.910706, time: 334 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebf42db6b294a158befcb7376a133e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e675aea9df54426a79cbd02b065c3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 lr: 0.000010; Train loss: 2.683126, Val loss: 4.910779, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11e51ea6df744459ea863365703d5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974d596a03e6479fa1ddddb106e1f55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 lr: 0.000010; Train loss: 2.682850, Val loss: 4.910852, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1206213657a4bceb2b76df8d0ccc424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43b8fe354904a7c981c03ca380c7877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 lr: 0.000010; Train loss: 2.682572, Val loss: 4.910926, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7b5cff4b084507a4a0cc30f9e8e69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f3282146e54323b388bfa28d34328c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 lr: 0.000010; Train loss: 2.682294, Val loss: 4.910999, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f0d60d6a44320bcd6e9139124cbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a522fae6b348e2bcb95ca91ac7d960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00037: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch: 36 lr: 0.000001; Train loss: 2.682016, Val loss: 4.911073, time: 328 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828249c97e7840d4ab17d8f4be2a19c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43922bbe0f9d49bfa68871493b79e94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 lr: 0.000001; Train loss: 2.681437, Val loss: 4.911084, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38fbd838d6e4bba986416e2e7678cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c81650bdd7416cb4e5afeeb5cccab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 lr: 0.000001; Train loss: 2.681409, Val loss: 4.911093, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fa9d763b6b4fad8e8e8623fde468dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d182f6e9ca0744609d7b0a18edfb6160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 lr: 0.000001; Train loss: 2.681381, Val loss: 4.911104, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae39bf60eaf14457b5db1ac5eb1b4183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27899eb5e2e44aca0194a232aced0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 lr: 0.000001; Train loss: 2.681352, Val loss: 4.911114, time: 333 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0451b95415747c98179d5a1e5a537e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb79d2fdfa3404aa63788e931547e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 lr: 0.000001; Train loss: 2.681324, Val loss: 4.911124, time: 337 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e1b7ac28734b75800353b065397489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89b7f8a33684014a89be4fd7c518475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch: 42 lr: 0.000000; Train loss: 2.681295, Val loss: 4.911134, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fcc7c52ef0423cb355728be2c47e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee7631705f1457a845008b443d5d17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 lr: 0.000000; Train loss: 2.681237, Val loss: 4.911135, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095d219874024af0a8094d0840d7ae39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f8007af9f64d98af9ea845b2df43b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 lr: 0.000000; Train loss: 2.681235, Val loss: 4.911136, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e84d626c8e42e9981aa21cf0358c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69e75c03f4e447380f1a374f6d5edcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 lr: 0.000000; Train loss: 2.681233, Val loss: 4.911137, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c655e071b0741b6841900b98d243725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b29fcf410f4b11ab3da94fab551913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 lr: 0.000000; Train loss: 2.681231, Val loss: 4.911138, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936dcc6e941c4e7ebff1f97109b31700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7244836988a64d4a8d1fc74ad67762c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 lr: 0.000000; Train loss: 2.681228, Val loss: 4.911139, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091853662bbb4c06a387b3d7a84e62da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1329653ee8af42159463fc11d2f66ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00049: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch: 48 lr: 0.000000; Train loss: 2.681226, Val loss: 4.911140, time: 335 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acd347985e740d582888f3e5d4c091d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55fd973e1564a2994ecaaa05054be6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 lr: 0.000000; Train loss: 2.681221, Val loss: 4.911140, time: 333 s\n",
      "end! 26.04.2023_04.42.21.074233_epoch_12_loss_4.7006\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.015)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "     \n",
    "best_model_name = train_model(0,\n",
    "    model, \n",
    "    DataLoader(train_dataset, batch_size=20000),\n",
    "    DataLoader(valid_dataset, batch_size=20000),\n",
    "    RMSE_loss, optimizer, 50, scheduler, loss_train_history, loss_val_history)\n",
    "print('end!', best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163754d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b996be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 8))    \n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_train_history, label='train loss')\n",
    "plt.plot(loss_val_history, label='val loss')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c06eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4060d523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1e37de4889404099d28a61842c808a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.677086505022915\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528b1afe8ca3492e80b9720ea8042d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.699917977506464\n"
     ]
    }
   ],
   "source": [
    "best_model = MfDotBias(120, len(user_lookup), len(movie_lookup), ratings_range=[-10, 10]).to(device)\n",
    "print(compute_accuracy(best_model, DataLoader(valid_dataset, batch_size=5000), RMSE_loss))\n",
    "\n",
    "load2(best_model_name, best_model)\n",
    "print(compute_accuracy(best_model, DataLoader(valid_dataset, batch_size=5000), RMSE_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a514f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39fb67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4ea9ab51f04059b5aab0b134ed2d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.700570583343506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c7c09f5dfc4aa7bdcf6622a62b0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7866526f5cc3436b9111c309dd90a66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 lr: 0.001000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c8ad49910d40efa037f9958dbe3fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae29dacf464420a8e34c7de78121a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 lr: 0.001000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2862fb6954974ead99189de4f1bf7bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137f9981df004289b9e52e47cc41304c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 lr: 0.001000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb81536412d84d20931f7bd261406974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2fd46d828743398be38e0ed0fc97c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 lr: 0.001000; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45b86cbc2ba4ccbb69c508b0d872a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da1083b03a941a798a71b826020361b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 lr: 0.001000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731f56f9051f448ba4f8b4182818d696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c293b22427604b3c8f6a74c6e87ffd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 lr: 0.001000; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15144fdc71b14f99972d72ca18d5fc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eea3fda43c4d5a8aefd8b27335050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 57 lr: 0.000100; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa5d9d4afea4281bb3b2137b4780afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2a79a4f38c4d4bbe71148d7673a8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 lr: 0.000100; Train loss: 3.954707, Val loss: 4.700571, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164d64b110bb40ce85215026a4a0f680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75324f222994379976f7af1834a567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 lr: 0.000100; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef91f6c678147b6a2d6a316e09661eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cfd1cca81a44f68e56dbef051fd963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 lr: 0.000100; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47915f7dfa614e8e87011bccb0db5c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead085746bdb41099f4f780528869f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 lr: 0.000100; Train loss: 3.954707, Val loss: 4.700571, time: 332 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662d1f533f434165ba4ac03f6e51aec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0799b89966b640a49b9e2f1a7adc5203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 lr: 0.000100; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fea9a146cd74f37ba018ea81d7d0e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae735496b90a428689c166813eefe380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch: 63 lr: 0.000010; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6958d9c5846d472985836f61635d3e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f847f81f8b844c27ab7dbd2a7563b3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 lr: 0.000010; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e3d212874245e493cc6489eb352ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d70cb825ffb49089a7b61ff7a8e2c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 lr: 0.000010; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0290848f21204e7ab653d18494dbe011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2e7559c37840799681d71316a856f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 lr: 0.000010; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaa4e612e504f49b63d8c24cd90a305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b6c797dd78442190abbfe3cee441b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 lr: 0.000010; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3141a37eb54d491a9ecc15e8b13b9d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc12a8ba91a45a8ad182d9b152e342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 lr: 0.000010; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc288de6a2a4f8bb408d196a1b5779d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039ea9571045477bbe4659f9f0a96b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch: 69 lr: 0.000001; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196f8ad31dc945a0af0ccbf7006221e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55f59dd5def4e44bee604f687601ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 lr: 0.000001; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bddb4ea5220450f90a09481bf17c859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2b08e640c4497a850d1885fb2bf362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71 lr: 0.000001; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f9fba167074b2eb06d2bd951fbb55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac648cd9300d402f8827ee00cb64d419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 lr: 0.000001; Train loss: 3.954707, Val loss: 4.700571, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726902830a9e45b2b871538633baea01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c626dd9a4e4faab5c4b2a95425fb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 lr: 0.000001; Train loss: 3.954707, Val loss: 4.700571, time: 332 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b11c6c3a6684f7a95b95e1ace117870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17ad37cda034f669f82bbde7141079e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 lr: 0.000001; Train loss: 3.954707, Val loss: 4.700571, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3beb2372ac4b5d80caaea6aa2df3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cd3d77e6b84285b9306638dcb65a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch: 75 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 332 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeebc4d6fa8e4b5fab1783341b2b7255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706df5137f754743b3a7de26b051afd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3936a8dd964e5a9c29a34724734245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c134d5c59744292b49f26124240845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cdaaeceacb434d9c9e726e3b46a604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e63e8d6feee402392e0df5a6194ce35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6302007a4e4898a90d14761638ecbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0c5c2d95bc4877ba4b82ee09e264a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 330 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d887d787445f39c5e735850753965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d86b285056a4f79965853b0e9b320c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c5634cf03e42f6816ba6a569e4dd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bada24b4e514909a1dc0a06a6b7741b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch: 81 lr: 0.000000; Train loss: 3.954707, Val loss: 4.700571, time: 329 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884c272fb5754e2a9cdcd5baf127c562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91d436264b540b2a4cbe3485d624ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Temp\\ipykernel_268\\3527303634.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 6&gt;</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\3527303634.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Temp\\ipykernel_268\\2873245106.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">36</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_model</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\2873245106.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Temp\\ipykernel_268\\2873245106.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">64</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_accuracy</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\2873245106.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\tqdm\\notebook.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">258</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">256 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">257 │   │   │   </span>it = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>(tqdm_notebook, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>258 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> it:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 │   │   │   │   # return super(tqdm...) will not catch exception</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   # NB: except ... [ as ...] breaks IPython async KeyboardInterrupt</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\tqdm\\std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1195</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span>time = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._time                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1194 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1195 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> iterable:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   │   │   # Update and possibly print the progressbar.</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1198 │   │   │   │   # Note: does not call self.update(1) for speed optimisation.</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">530</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 527 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.autograd.profiler.record_function(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._profile_name):                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 530 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">570</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 567 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 568 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 569 │   │   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 570 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 571 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 572 │   │   │   </span>data = _utils.pin_memory.pin_memory(data)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 573 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, possibly_batched_index):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.auto_collation:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>49 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, possibly_batched_index):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.auto_collation:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>49 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Temp\\ipykernel_268\\349431671.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\349431671.py'</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Temp\\ipykernel_268\\3527303634.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<cell line: 6>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\3527303634.py'\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Temp\\ipykernel_268\\2873245106.py\u001b[0m:\u001b[94m36\u001b[0m in \u001b[92mtrain_model\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\2873245106.py'\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Temp\\ipykernel_268\\2873245106.py\u001b[0m:\u001b[94m64\u001b[0m in \u001b[92mcompute_accuracy\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\2873245106.py'\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m:\u001b[94m258\u001b[0m in \u001b[92m__iter__\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m255 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m):                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2m│   │   │   \u001b[0mit = \u001b[96msuper\u001b[0m(tqdm_notebook, \u001b[96mself\u001b[0m).\u001b[92m__iter__\u001b[0m()                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m258 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m it:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# return super(tqdm...) will not catch exception\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\tqdm\\std.py\u001b[0m:\u001b[94m1195\u001b[0m in \u001b[92m__iter__\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0mtime = \u001b[96mself\u001b[0m._time                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1194 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1195 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m iterable:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Update and possibly print the progressbar.\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1198 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Note: does not call self.update(1) for speed optimisation.\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:\u001b[94m530\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__next__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 527 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.autograd.profiler.record_function(\u001b[96mself\u001b[0m._profile_name):                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 530 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:\u001b[94m570\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_next_data\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 567 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 568 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 569 \u001b[0m\u001b[2m│   │   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 570 \u001b[2m│   │   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 571 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 572 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = _utils.pin_memory.pin_memory(data)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 573 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:\u001b[94m49\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfetch\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfetch\u001b[0m(\u001b[96mself\u001b[0m, possibly_batched_index):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_collation:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m49 \u001b[2m│   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:\u001b[94m49\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<listcomp>\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfetch\u001b[0m(\u001b[96mself\u001b[0m, possibly_batched_index):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_collation:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m49 \u001b[2m│   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Temp\\ipykernel_268\\349431671.py\u001b[0m:\u001b[94m14\u001b[0m in \u001b[92m__getitem__\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Temp\\\\ipykernel_268\\\\349431671.py'\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.05)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "     \n",
    "best_model_name = train_model(51,\n",
    "    best_model, \n",
    "    DataLoader(train_dataset, batch_size=20000),\n",
    "    DataLoader(valid_dataset, batch_size=20000),\n",
    "    RMSE_loss, optimizer, 50, scheduler, loss_train_history, loss_val_history)\n",
    "print('end!', best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bb2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a768732",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3976f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UserItemRatingDataset(train_joke_df, movie_lookup, user_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "best_model_name2 = train_model(101,\n",
    "    best_model, \n",
    "    DataLoader(dataset, batch_size=10000),\n",
    "    DataLoader(valid_dataset, batch_size=10000),\n",
    "    RMSE_loss, optimizer, 6, None, loss_train_history, loss_val_history)\n",
    "print('end!', best_model_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))    \n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_train_history, label='train loss')\n",
    "plt.plot(loss_val_history, label='val loss')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281558f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afaacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1a260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140ab2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_joke_df_nofactrating = pd.read_csv(r'..\\data\\recsys-in-practice\\test_joke_df_nofactrating.csv', index_col=0)\n",
    "\n",
    "test_joke_df_nofactrating['Rating'] = np.zeros((len(test_joke_df_nofactrating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserItemRatingDataset(test_joke_df_nofactrating, movie_lookup, user_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_name = '22.04.2023_22.36.11.670000_epoch_25_loss_4.8642'\n",
    "\n",
    "#best_model = MfDotBias(120, len(user_lookup), len(movie_lookup), ratings_range=[-10, 10]).to(device)\n",
    "#print(compute_accuracy(best_model, DataLoader(test_dataset, batch_size=5000), RMSE_loss))\n",
    "\n",
    "#load2(best_model_name, best_model)\n",
    "#print(compute_accuracy(best_model, DataLoader(test_dataset, batch_size=5000), RMSE_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for x, y in tqdm(DataLoader(test_dataset, batch_size=5000)):\n",
    "    predict = model(x)\n",
    "    result.extend(predict.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_joke_df_nofactrating['Rating'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_joke_df_nofactrating['Rating'].to_frame().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_joke_df_nofactrating['Rating'].to_frame().to_csv('nn_embedding_120.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c17f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3d353",
   "metadata": {},
   "source": [
    "Comparing this to our baseline, we can see that there is an improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b89b19",
   "metadata": {},
   "source": [
    "## Sequential recommendations using a transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb857b",
   "metadata": {},
   "source": [
    "Using matrix factorization, we are treating each rating as being independent from the ratings around it; however, incorporating information about other movies that a user recently rated could provide an additional signal that could boost performance. For example, suppose that a user is watching a trilogy of films; if they have rated the first two instalments highly, it is likely that they may do the same for the finale!\n",
    "\n",
    "One way that we can approach this is to use a transformer network, specifically the encoder portion, to encode additional context into the learned embeddings for each movie, and then using a fully connected neural network to make the rating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c308a7",
   "metadata": {},
   "source": [
    "### Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b22435",
   "metadata": {},
   "source": [
    "The first step is to process our data so that we have a time-sorted list of movies for each user. Let's start by grouping all the ratings by user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ratings = train_joke_df.groupby('UID').agg(tuple).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ca0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f7e51",
   "metadata": {},
   "source": [
    "Now that we have grouped by user, we can create an additional column so that we can see the number of events associated with each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ratings['num_ratings'] = grouped_ratings['Rating'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103612b7",
   "metadata": {},
   "source": [
    "Let's take a look at the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0db536",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8559845",
   "metadata": {},
   "source": [
    "Now that we have grouped all the ratings for each user, let's divide these into smaller sequences. To make the most out of the data, we would like the model to have the opportunity to predict a rating for every movie in the training set. To do this, let's specify a sequence length s and use the previous s-1 ratings as our user history.\n",
    "\n",
    "As the model expects each sequence to be a fixed length, we will fill empty spaces with a padding token, so that sequences can be batched and passed to the model. Let's create a function to do this.\n",
    "\n",
    "We are going to arbitrarily choose a length of 10 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00164996",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09119db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(values, sequence_length):\n",
    "    sequences = []\n",
    "    for i, v in enumerate(values):\n",
    "        seq = values[:i+1]\n",
    "        if len(seq) > sequence_length:\n",
    "            seq = seq[i-sequence_length+1:i+1]\n",
    "        elif len(seq) < sequence_length:\n",
    "            seq =(*(['[PAD]'] * (sequence_length - len(seq))), *seq)\n",
    "       \n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310980e",
   "metadata": {},
   "source": [
    "To visualize how this function works, let's apply it, with a sequence length of 3, to the first 10 movies rated by the first user. These movies are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f08327",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ratings.iloc[0]['title'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1db720",
   "metadata": {},
   "source": [
    "Applying our function, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee50596",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sequences(grouped_ratings.iloc[0]['JID'][:10], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93d0cf",
   "metadata": {},
   "source": [
    "As we can see, we have 10 sequences of length 3, where the final movie in the sequence is unchanged from the original list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79f074",
   "metadata": {},
   "source": [
    "Now, let's apply this function to all of the features in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed431a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cols = ['title', 'rating', 'unix_timestamp', 'is_valid'] \n",
    "for col in grouped_cols:\n",
    "    grouped_ratings[col] = grouped_ratings[col].apply(lambda x: create_sequences(x, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ratings.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fa619",
   "metadata": {},
   "source": [
    "Currently, we have one row that contains all the sequences for a certain user. However, during training, we would like to create batches made up of sequences from many different users. To do this, we will have to transform the data so that each sequence has its own row, while remaining associated with the user ID. We can use the pandas 'explode' function for each feature, and then aggregate these DataFrames together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_ratings = grouped_ratings[['user_id', 'title']].explode('title', ignore_index=True)\n",
    "dfs = [grouped_ratings[[col]].explode(col, ignore_index=True) for col in grouped_cols[1:]]\n",
    "seq_df = pd.concat([exploded_ratings, *dfs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5af3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea5a39",
   "metadata": {},
   "source": [
    "Now, we can see that each sequence has its own row. However, for the is_valid column, we don't care about the whole sequence and only need the last value as this is the movie for which we will be trying to predict the rating. Let's create a function to extract this value and apply it to these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9279a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_entry(sequence):\n",
    "    return sequence[-1]\n",
    "\n",
    "seq_df['is_valid'] = seq_df['is_valid'].apply(get_last_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ce4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cd447",
   "metadata": {},
   "source": [
    "Also, to make it easy to access the rating that we are trying to predict, let's separate this into its own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df['target_rating'] = seq_df['rating'].apply(get_last_entry)\n",
    "seq_df['previous_ratings'] = seq_df['rating'].apply(lambda seq: seq[:-1])\n",
    "seq_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552504c",
   "metadata": {},
   "source": [
    "To prevent the model from including padding tokens when calculating attention scores, we can provide an attention mask to the transformer; the mask should be 'True' for a padding token and 'False' otherwise. Let's calculate this for each row, as well as creating a column to show the number of padding tokens present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df['pad_mask'] = seq_df['title'].apply(lambda x: (np.array(x) == '[PAD]'))\n",
    "seq_df['num_pads'] = seq_df['pad_mask'].apply(sum)\n",
    "seq_df['pad_mask'] = seq_df['pad_mask'].apply(lambda x: x.tolist()) # in case we serialize later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99057816",
   "metadata": {},
   "source": [
    "Let's inspect the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5fead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893972ae",
   "metadata": {},
   "source": [
    "All looks as it should! Let's split this into training and validation sets and save this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_df = seq_df[seq_df.is_valid == False]\n",
    "valid_seq_df = seq_df[seq_df.is_valid == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69a8a2",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46b06f",
   "metadata": {},
   "source": [
    "As we saw previously, before we can feed this data into the model, we need to create lookup tables to encode our movies and users. However, this time, we need to include the padding token in our movie lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440df620",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lookup = {v: i+1 for i, v in enumerate(ratings_df['user_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_lookup(df, feature):\n",
    "    lookup = {v: i+1 for i, v in enumerate(df[feature].unique())}\n",
    "    lookup['[PAD]'] = 0\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lookup = create_feature_lookup(ratings_df, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21228dbc",
   "metadata": {},
   "source": [
    "Now, we are dealing with sequences of ratings, rather than individual ones, so we will need to create a new dataset to wrap our processed DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0648f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieSequenceDataset(Dataset):\n",
    "    def __init__(self, df, movie_lookup, user_lookup):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.movie_lookup = movie_lookup\n",
    "        self.user_lookup = user_lookup\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.iloc[index]\n",
    "        user_id = torch.tensor(self.user_lookup[str(data.user_id)])\n",
    "        movie_ids = torch.tensor([self.movie_lookup[title] for title in data.title])\n",
    "\n",
    "        previous_ratings = torch.tensor(\n",
    "            [rating if rating != \"[PAD]\" else 0 for rating in data.previous_ratings]\n",
    "        )\n",
    "\n",
    "        attention_mask = torch.tensor(data.pad_mask).to(device)\n",
    "        target_rating = data.target_rating\n",
    "        encoded_features = {\n",
    "            \"user_id\": user_id.to(device),\n",
    "            \"movie_ids\": movie_ids.to(device),\n",
    "            \"ratings\": previous_ratings.to(device),\n",
    "        }\n",
    "\n",
    "        return (encoded_features, attention_mask), torch.tensor(target_rating, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41854545",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieSequenceDataset(train_seq_df, movie_lookup, user_lookup)\n",
    "valid_dataset = MovieSequenceDataset(valid_seq_df, movie_lookup, user_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee81f6",
   "metadata": {},
   "source": [
    "Now, let's define our transformer model! As a start, given that the matrix factorization model can achieve good performance using only the user and movie ids, let's only include this information for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BstTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        movies_num_unique,\n",
    "        users_num_unique,\n",
    "        sequence_length=10,\n",
    "        embedding_size=120,\n",
    "        num_transformer_layers=1,\n",
    "        ratings_range=(0.5, 5.5),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y_range = ratings_range\n",
    "        self.movies_embeddings = nn.Embedding(movies_num_unique + 1, embedding_size, padding_idx=0)\n",
    "        self.user_embeddings = nn.Embedding(users_num_unique + 1, embedding_size)\n",
    "        self.position_embeddings = nn.Embedding(sequence_length, embedding_size)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_size,\n",
    "                nhead=12,\n",
    "                dropout=0.1,\n",
    "                batch_first=True,\n",
    "                activation=\"gelu\",\n",
    "            ),\n",
    "            num_layers=num_transformer_layers,\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embedding_size + (embedding_size * sequence_length), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features, mask = inputs\n",
    "\n",
    "        encoded_user_id = self.user_embeddings(features[\"user_id\"])\n",
    "\n",
    "        user_features = encoded_user_id\n",
    "\n",
    "        encoded_movies = self.movies_embeddings(features[\"movie_ids\"])\n",
    "\n",
    "        positions = torch.arange(0, self.sequence_length, 1, dtype=int, device=features[\"movie_ids\"].device)\n",
    "        positions = self.position_embeddings(positions)\n",
    "\n",
    "        transformer_features = encoded_movies + positions\n",
    "\n",
    "        transformer_output = self.encoder(transformer_features, src_key_padding_mask=mask)\n",
    "        transformer_output = torch.flatten(transformer_output, start_dim=1)\n",
    "\n",
    "        combined_output = torch.cat((transformer_output, user_features), dim=1)\n",
    "\n",
    "        rating = self.linear(combined_output)\n",
    "        rating = rating.squeeze()\n",
    "        if self.y_range is None:\n",
    "            return rating\n",
    "        else:\n",
    "            return rating * (self.y_range[1] - self.y_range[0]) + self.y_range[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26939213",
   "metadata": {},
   "source": [
    "We can see that, as a default, we feed our sequence of movie embeddings into a single transformer layer, before concatenating the output with the user features - here, just the user ID - and using this as the input to a fully connected network. Here, we are using only a simple positional encoding that is learned to represent the sequence in which the movies were rated; using a sine- and cosine-based approach provided no benefit during my experiments, but feel free to try it out if you are interested!\n",
    "\n",
    "Once again, let's define a training function for this model; except for the model initialization, this is identical to the one we used to train the matrix factorization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef19722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f207c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2143f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in tqdm(DataLoader(train_dataset, batch_size=8)):\n",
    "    #print(images[0].shape, texts[0], labels[0] , labels.shape)\n",
    "    break\n",
    "display(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc75dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67ee7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26164c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for xx in x:\n",
    "#    display(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[{key:xx[key] for key in xx} for xx in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed314da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler, loss_train_history, loss_val_history):    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss_accum = 0\n",
    "        t1 = time.time()\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "            prediction = model(x)    \n",
    "            loss_value = loss(prediction, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / (i_step + 1)\n",
    "        loss_val = compute_accuracy(model, val_loader, loss)\n",
    "        \n",
    "        loss_train_history.append(float(ave_loss))\n",
    "        loss_val_history.append(loss_val)\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        print(\"Epoch: %i lr: %f; Train loss: %f, Val loss: %f, time: %i s\" % (epoch, get_lr(optimizer), ave_loss, loss_val,\n",
    "                                                                            round(time.time() - t1)))\n",
    "    return loss_train_history, loss_val_history\n",
    "        \n",
    "    \n",
    "def compute_accuracy(model, loader, loss):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    loss_accum = 0\n",
    "    for i_step, (x, y) in enumerate(loader):\n",
    "        prediction = model(x)\n",
    "        loss_value = loss(prediction, y)\n",
    "        loss_accum += loss_value\n",
    "\n",
    "    ave_loss = loss_accum / (i_step + 1)         \n",
    "    return float(ave_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BstTransformer(len(movie_lookup), len(user_lookup), sequence_length, embedding_size=120).to(device)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "loss_train_history = []\n",
    "loss_val_history = []\n",
    "train_model(\n",
    "    model, \n",
    "    DataLoader(train_dataset, batch_size=10000),\n",
    "    DataLoader(valid_dataset, batch_size=10000),\n",
    "    loss_func, optimizer, 30, scheduler, loss_train_history, loss_val_history)\n",
    "print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))    \n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_train_history, label='train loss')\n",
    "plt.plot(loss_val_history, label='val loss')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893bae86",
   "metadata": {},
   "source": [
    "We can see that this is a significant improvement over the matrix factorization approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae00c3",
   "metadata": {},
   "source": [
    "### Adding additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fab57",
   "metadata": {},
   "source": [
    "So far, we have only considered the user ID and a sequence of movie IDs to predict the rating; it seems likely that including information about the previous ratings made by the user would improve performance. Thankfully, this is easy to do, and the data is already being returned by our dataset. Let's tweak our architecture to include this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4425d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BstTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        movies_num_unique,\n",
    "        users_num_unique,\n",
    "        sequence_length=10,\n",
    "        embedding_size=120,\n",
    "        num_transformer_layers=1,\n",
    "        ratings_range=(0.5, 5.5),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y_range = ratings_range\n",
    "        self.movies_embeddings = nn.Embedding(\n",
    "            movies_num_unique + 1, embedding_size, padding_idx=0\n",
    "        )\n",
    "        self.user_embeddings = nn.Embedding(users_num_unique + 1, embedding_size)\n",
    "        self.ratings_embeddings = nn.Embedding(6, embedding_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(sequence_length, embedding_size)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_size,\n",
    "                nhead=12,\n",
    "                dropout=0.1,\n",
    "                batch_first=True,\n",
    "                activation=\"gelu\",\n",
    "            ),\n",
    "            num_layers=num_transformer_layers,\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                embedding_size + (embedding_size * sequence_length),\n",
    "                1024,\n",
    "            ),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features, mask = inputs\n",
    "\n",
    "        encoded_user_id = self.user_embeddings(features[\"user_id\"])\n",
    "\n",
    "        user_features = encoded_user_id\n",
    "\n",
    "        movie_history = features[\"movie_ids\"][:, :-1]\n",
    "        target_movie = features[\"movie_ids\"][:, -1]\n",
    "\n",
    "        ratings = self.ratings_embeddings(features[\"ratings\"])\n",
    "\n",
    "        encoded_movies = self.movies_embeddings(movie_history)\n",
    "        encoded_target_movie = self.movies_embeddings(target_movie)\n",
    "\n",
    "        positions = torch.arange(\n",
    "            0,\n",
    "            self.sequence_length - 1,\n",
    "            1,\n",
    "            dtype=int,\n",
    "            device=features[\"movie_ids\"].device,\n",
    "        )\n",
    "        positions = self.position_embeddings(positions)\n",
    "\n",
    "        encoded_sequence_movies_with_position_and_rating = (\n",
    "            encoded_movies + ratings + positions\n",
    "        )\n",
    "        encoded_target_movie = encoded_target_movie.unsqueeze(1)\n",
    "\n",
    "        transformer_features = torch.cat(\n",
    "            (encoded_sequence_movies_with_position_and_rating, encoded_target_movie),\n",
    "            dim=1,\n",
    "        )\n",
    "        transformer_output = self.encoder(\n",
    "            transformer_features, src_key_padding_mask=mask\n",
    "        )\n",
    "        transformer_output = torch.flatten(transformer_output, start_dim=1)\n",
    "\n",
    "        combined_output = torch.cat((transformer_output, user_features), dim=1)\n",
    "\n",
    "        rating = self.linear(combined_output)\n",
    "        rating = rating.squeeze()\n",
    "        if self.y_range is None:\n",
    "            return rating\n",
    "        else:\n",
    "            return rating * (self.y_range[1] - self.y_range[0]) + self.y_range[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcbf1a",
   "metadata": {},
   "source": [
    "We can see that, to use the ratings data, we have added an additional embedding layer. For each previously rated movie, we then add together the movie embedding, the positional encoding and the rating embedding before feeding this sequence into the transformer. Alternatively, the rating data could be concatenated to, or multiplied with, the movie embedding, but adding them together worked the best out of the approaches that I tried.\n",
    "\n",
    "As Jupyter maintains a live state for each class definition, we don't need to update our training function; the new class will be used when we launch training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd1f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BstTransformer(len(movie_lookup), len(user_lookup), sequence_length, embedding_size=120).to(device)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "\n",
    "loss_train_history = []\n",
    "loss_val_history = []\n",
    "train_model(\n",
    "    model, \n",
    "    DataLoader(train_dataset, batch_size=10000),\n",
    "    DataLoader(valid_dataset, batch_size=10000),\n",
    "    loss_func, optimizer, 30, scheduler, loss_train_history, loss_val_history)\n",
    "print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))    \n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_train_history, label='train loss')\n",
    "plt.plot(loss_val_history, label='val loss')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04257221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56896157",
   "metadata": {},
   "source": [
    "We can see that incorporating the ratings data has improved our results slightly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96290024",
   "metadata": {},
   "source": [
    "### Adding user features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61193109",
   "metadata": {},
   "source": [
    "In addition to the ratings data, we also have more information about the users that we could add into the model. To remind ourselves, let's take a look at the users table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ba262",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b10c1",
   "metadata": {},
   "source": [
    "Let's try adding in the categorical variables representing the users' sex, age groups, and occupation to the model, and see if we see any improvement. While occupation looks like it is already sequentially numerically encoded, we must do the same for the sex and age_group columns. We can use the 'LabelEncoder' class from scikit-learn to do this for us, and append the encoded columns to the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed11ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355472a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1fda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['sex_encoded'] = le.fit_transform(users.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bef9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['age_group_encoded'] = le.fit_transform(users.age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39baba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "users[\"user_id\"] = users[\"user_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684dd4b",
   "metadata": {},
   "source": [
    "Now that we have all the features that we are going to use encoded, let's join the user features to our sequences DataFrame, and update our training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_with_user_features = pd.merge(seq_df, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = seq_with_user_features[seq_with_user_features.is_valid == False]\n",
    "valid_df = seq_with_user_features[seq_with_user_features.is_valid == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100ddbc",
   "metadata": {},
   "source": [
    "Let's update our dataset to include these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieSequenceDataset(Dataset):\n",
    "    def __init__(self, df, movie_lookup, user_lookup):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.movie_lookup = movie_lookup\n",
    "        self.user_lookup = user_lookup\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.iloc[index]\n",
    "        user_id = torch.tensor(self.user_lookup[str(data.user_id)]).to(device)\n",
    "        movie_ids = torch.tensor([self.movie_lookup[title] for title in data.title]).to(device)\n",
    "\n",
    "        previous_ratings = torch.tensor(\n",
    "            [rating if rating != \"[PAD]\" else 0 for rating in data.previous_ratings]\n",
    "        ).to(device)\n",
    "\n",
    "        attention_mask = torch.tensor(data.pad_mask).to(device)\n",
    "        target_rating = data.target_rating\n",
    "        encoded_features = {\n",
    "            \"user_id\": user_id,\n",
    "            \"movie_ids\": movie_ids,\n",
    "            \"ratings\": previous_ratings,\n",
    "            \"age_group\": torch.tensor(data[\"age_group_encoded\"]).to(device),\n",
    "            \"sex\": torch.tensor(data[\"sex_encoded\"]).to(device),\n",
    "            \"occupation\": torch.tensor(data[\"occupation\"]).to(device),\n",
    "        }\n",
    "\n",
    "        return (encoded_features, attention_mask), torch.tensor(\n",
    "            target_rating, dtype=torch.float32\n",
    "        ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d48d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieSequenceDataset(train_df, movie_lookup, user_lookup)\n",
    "valid_dataset = MovieSequenceDataset(valid_df, movie_lookup, user_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0a744",
   "metadata": {},
   "source": [
    "We can now modify our architecture to include embeddings for these features and concatenate these embeddings to the output of the transformer; then we pass this into the feed-forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BstTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        movies_num_unique,\n",
    "        users_num_unique,\n",
    "        sequence_length=10,\n",
    "        embedding_size=120,\n",
    "        num_transformer_layers=1,\n",
    "        ratings_range=(0.5, 5.5),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y_range = ratings_range\n",
    "        self.movies_embeddings = nn.Embedding(\n",
    "            movies_num_unique + 1, embedding_size, padding_idx=0\n",
    "        )\n",
    "        self.user_embeddings = nn.Embedding(users_num_unique + 1, embedding_size)\n",
    "        self.ratings_embeddings = nn.Embedding(6, embedding_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(sequence_length, embedding_size)\n",
    "\n",
    "        self.sex_embeddings = nn.Embedding(\n",
    "            3,\n",
    "            2,\n",
    "        )\n",
    "        self.occupation_embeddings = nn.Embedding(\n",
    "            22,\n",
    "            11,\n",
    "        )\n",
    "        self.age_group_embeddings = nn.Embedding(\n",
    "            8,\n",
    "            4,\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_size,\n",
    "                nhead=12,\n",
    "                dropout=0.1,\n",
    "                batch_first=True,\n",
    "                activation=\"gelu\",\n",
    "            ),\n",
    "            num_layers=num_transformer_layers,\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                embedding_size + (embedding_size * sequence_length) + 4 + 11 + 2,\n",
    "                1024,\n",
    "            ),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features, mask = inputs\n",
    "\n",
    "        user_id = self.user_embeddings(features[\"user_id\"])\n",
    "\n",
    "        age_group = self.age_group_embeddings(features[\"age_group\"])\n",
    "        sex = self.sex_embeddings(features[\"sex\"])\n",
    "        occupation = self.occupation_embeddings(features[\"occupation\"])\n",
    "\n",
    "        user_features = user_features = torch.cat(\n",
    "            (user_id, sex, age_group, occupation), 1\n",
    "        )\n",
    "\n",
    "        movie_history = features[\"movie_ids\"][:, :-1]\n",
    "        target_movie = features[\"movie_ids\"][:, -1]\n",
    "\n",
    "        ratings = self.ratings_embeddings(features[\"ratings\"])\n",
    "\n",
    "        encoded_movies = self.movies_embeddings(movie_history)\n",
    "        encoded_target_movie = self.movies_embeddings(target_movie)\n",
    "\n",
    "        positions = torch.arange(\n",
    "            0,\n",
    "            self.sequence_length - 1,\n",
    "            1,\n",
    "            dtype=int,\n",
    "            device=features[\"movie_ids\"].device,\n",
    "        )\n",
    "        positions = self.position_embeddings(positions)\n",
    "\n",
    "        encoded_sequence_movies_with_position_and_rating = (\n",
    "            encoded_movies + ratings + positions\n",
    "        )\n",
    "        encoded_target_movie = encoded_target_movie.unsqueeze(1)\n",
    "\n",
    "        transformer_features = torch.cat(\n",
    "            (encoded_sequence_movies_with_position_and_rating, encoded_target_movie),\n",
    "            dim=1,\n",
    "        )\n",
    "        transformer_output = self.encoder(\n",
    "            transformer_features, src_key_padding_mask=mask\n",
    "        )\n",
    "        transformer_output = torch.flatten(transformer_output, start_dim=1)\n",
    "\n",
    "        combined_output = torch.cat((transformer_output, user_features), dim=1)\n",
    "\n",
    "        rating = self.linear(combined_output)\n",
    "        rating = rating.squeeze()\n",
    "        if self.y_range is None:\n",
    "            return rating\n",
    "        else:\n",
    "            return rating * (self.y_range[1] - self.y_range[0]) + self.y_range[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7abc27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BstTransformer(len(movie_lookup), len(user_lookup), sequence_length, embedding_size=120).to(device)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "\n",
    "loss_train_history = []\n",
    "loss_val_history = []\n",
    "train_model(\n",
    "    model, \n",
    "    DataLoader(train_dataset, batch_size=10000),\n",
    "    DataLoader(valid_dataset, batch_size=10000),\n",
    "    loss_func, optimizer, 30, scheduler, loss_train_history, loss_val_history)\n",
    "print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d737f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))    \n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_train_history, label='train loss')\n",
    "plt.plot(loss_val_history, label='val loss')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e17bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab3e0f1",
   "metadata": {},
   "source": [
    "Here, we can see a slight decrease in the MAE, but a small increase in the MSE and RMSE, so it looks like these features made a negligible difference to the overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fcbe21",
   "metadata": {},
   "source": [
    "In writing this article, my main objective has been to try and illustrate how these approaches can be used, and so I've picked the hyperparameters somewhat arbitrarily; it's likely that with some hyperparameter tweaks, and different combinations of features, these metrics can probably be improved upon!\n",
    "\n",
    "Hopefully this has provided a good introduction to using both matrix factorization and transformer-based approaches in PyTorch, and how pytorch-accelerated can speed up our process when experimenting with different models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86dfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Comparing matrix factorixation with transformers using pytorch-accelerated blog post.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
